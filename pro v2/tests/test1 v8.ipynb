{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Predicted adjective: 5. Beautiful (Confidence: 0.8874)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('D:/code/Mini/pro v2/isl_model_v8.keras')\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Initialize MediaPipe Holistic and Drawing utilities\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Adjective labels\n",
    "adjectives = ['1. loud', '2. quiet', '3. happy', '4. sad', '5. Beautiful', '6. Ugly', '7. Deaf', '8. Blind']\n",
    "\n",
    "# Function to extract landmarks from a video\n",
    "def extract_landmarks_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    landmarks = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert the frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        frame_landmarks = []\n",
    "        # Pose landmarks\n",
    "        if results.pose_landmarks:\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                frame_landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "        else:\n",
    "            frame_landmarks.extend([0.0] * 132)  # 33 landmarks × 4\n",
    "        \n",
    "        # Left hand landmarks\n",
    "        if results.left_hand_landmarks:\n",
    "            for landmark in results.left_hand_landmarks.landmark:\n",
    "                frame_landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
    "        else:\n",
    "            frame_landmarks.extend([0.0] * 63)  # 21 landmarks × 3\n",
    "        \n",
    "        # Right hand landmarks\n",
    "        if results.right_hand_landmarks:\n",
    "            for landmark in results.right_hand_landmarks.landmark:\n",
    "                frame_landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
    "        else:\n",
    "            frame_landmarks.extend([0.0] * 63)  # 21 landmarks × 3\n",
    "        \n",
    "        landmarks.append(frame_landmarks)\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(landmarks)\n",
    "\n",
    "# Function to preprocess landmarks (same as training)\n",
    "def preprocess_landmarks(landmarks, max_len=80):\n",
    "    # Pad or truncate to max_len\n",
    "    padded_data = pad_sequences([landmarks], maxlen=max_len, padding='post', truncating='post', dtype='float32')[0]\n",
    "    \n",
    "    # Smooth the data (moving average)\n",
    "    def moving_average(data, window_size=3):\n",
    "        smoothed_data = np.copy(data)\n",
    "        for j in range(data.shape[1]):  # Iterate over features\n",
    "            smoothed_data[:, j] = np.convolve(data[:, j], np.ones(window_size)/window_size, mode='same')\n",
    "        return smoothed_data\n",
    "    \n",
    "    padded_data = moving_average(padded_data, window_size=3)\n",
    "    \n",
    "    # Normalize (using approximate mean and std from training data)\n",
    "    # Ideally, you should load the mean and std from training\n",
    "    padded_data_reshaped = padded_data.reshape(-1, 258)\n",
    "    mean = np.mean(padded_data_reshaped, axis=0)\n",
    "    std = np.std(padded_data_reshaped, axis=0)\n",
    "    std[std == 0] = 1\n",
    "    padded_data_reshaped = (padded_data_reshaped - mean) / std\n",
    "    padded_data = padded_data_reshaped.reshape(max_len, 258)\n",
    "    \n",
    "    # Reshape for model input (1, max_len, 258)\n",
    "    return np.expand_dims(padded_data, axis=0)\n",
    "\n",
    "# Function to predict the adjective\n",
    "def predict_adjective(landmarks):\n",
    "    if landmarks.shape[0] == 0:\n",
    "        return \"Error: No landmarks detected\", 0.0\n",
    "    \n",
    "    # Preprocess landmarks\n",
    "    processed_landmarks = preprocess_landmarks(landmarks)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(processed_landmarks, verbose=0)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_label = adjectives[predicted_class]\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    return predicted_label, confidence\n",
    "\n",
    "# Function to play video and plot landmarks\n",
    "def play_video_with_landmarks(video_path):\n",
    "    # First, extract landmarks and predict the adjective\n",
    "    landmarks = extract_landmarks_from_video(video_path)\n",
    "    predicted_label, confidence = predict_adjective(landmarks)\n",
    "    print(f\"Predicted adjective: {predicted_label} (Confidence: {confidence:.4f})\")\n",
    "    \n",
    "    # Reopen the video to play it with landmarks\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert the frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "        \n",
    "        # Convert back to BGR for OpenCV\n",
    "        frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame_bgr, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)\n",
    "            )\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame_bgr, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2)\n",
    "            )\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame_bgr, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2)\n",
    "            )\n",
    "        \n",
    "        # Display the prediction on the frame\n",
    "        text = f\"Prediction: {predicted_label} ({confidence:.2f})\"\n",
    "        cv2.putText(frame_bgr, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show the frame\n",
    "        cv2.imshow('Video with Landmarks', frame_bgr)\n",
    "        \n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    holistic.close()\n",
    "\n",
    "# Test on a new video\n",
    "video_path = 'D:/code/Mini/Adjectives/5. Beautiful/MVI_9723.MOV'  # Replace with your video path\n",
    "play_video_with_landmarks(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
