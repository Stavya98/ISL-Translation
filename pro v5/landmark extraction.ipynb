{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36748833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Extract keypoints from frame\n",
    "def extract_landmarks(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 3)\n",
    "    left = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    right = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    return np.concatenate([pose, left, right])  # total 225 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561cf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence_from_video(video_path, max_frames=110):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    sequence = []\n",
    "\n",
    "    with mp_holistic.Holistic(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = holistic.process(image)\n",
    "            image.flags.writeable = True\n",
    "\n",
    "            keypoints = extract_landmarks(results)\n",
    "            sequence.append(keypoints)\n",
    "\n",
    "            if len(sequence) >= max_frames:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11ed9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 225)\n"
     ]
    }
   ],
   "source": [
    "sequence = extract_sequence_from_video(\"D:/code/Mini/Final data/40. I/MVI_0001.MOV\")\n",
    "print(sequence.shape)  # should be (<=110, 225)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b18c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAX_FRAMES = 110  # maximum frame length to extract\\n\\n# Create output folder if it doesn\\'t exist\\nos.makedirs(OUTPUT_PATH, exist_ok=True)\\n\\nfor word in os.listdir(DATASET_PATH):\\n    word_path = os.path.join(DATASET_PATH, word)\\n    save_path = os.path.join(OUTPUT_PATH, word)\\n    os.makedirs(save_path, exist_ok=True)\\n\\n    for video_file in tqdm(os.listdir(word_path), desc=f\"Processing \\'{word}\\'\"):\\n        video_path = os.path.join(word_path, video_file)\\n\\n        try:\\n            sequence = extract_sequence_from_video(video_path, max_frames=MAX_FRAMES)\\n            filename = os.path.splitext(video_file)[0] + \\'.npy\\'\\n            np.save(os.path.join(save_path, filename), sequence)\\n        except Exception as e:\\n            print(f\"Error processing {video_file}: {e}\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATASET_PATH = 'D:/code/Mini/Final data'\n",
    "OUTPUT_PATH = 'D:/code/Mini/pro v5/extracted_sequences'\n",
    "MAX_FRAMES = 110  # maximum frame length to extract\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "for word in os.listdir(DATASET_PATH):\n",
    "    word_path = os.path.join(DATASET_PATH, word)\n",
    "    save_path = os.path.join(OUTPUT_PATH, word)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    for video_file in tqdm(os.listdir(word_path), desc=f\"Processing '{word}'\"):\n",
    "        video_path = os.path.join(word_path, video_file)\n",
    "\n",
    "        try:\n",
    "            sequence = extract_sequence_from_video(video_path, max_frames=MAX_FRAMES)\n",
    "            filename = os.path.splitext(video_file)[0] + '.npy'\n",
    "            np.save(os.path.join(save_path, filename), sequence)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77dded5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2198, 110, 225)\n",
      "y shape: (2198,)\n"
     ]
    }
   ],
   "source": [
    "MAX_FRAMES = 110  # maximum frame length to extract\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X, y = [], []\n",
    "labels = []\n",
    "\n",
    "for word in os.listdir(OUTPUT_PATH):\n",
    "    word_path = os.path.join(OUTPUT_PATH, word)\n",
    "    for file in os.listdir(word_path):\n",
    "        sequence = np.load(os.path.join(word_path, file))\n",
    "\n",
    "        # Pad/truncate\n",
    "        if sequence.shape[0] < MAX_FRAMES:\n",
    "            pad_len = MAX_FRAMES - sequence.shape[0]\n",
    "            padding = np.zeros((pad_len, 225))\n",
    "            sequence = np.vstack((sequence, padding))\n",
    "        else:\n",
    "            sequence = sequence[:MAX_FRAMES]\n",
    "\n",
    "        X.append(sequence)\n",
    "        y.append(word)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"X shape:\", X.shape)  # should be (num_samples, 110, 225)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230dbaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['18. City' '19. House' '20. Street or Road' '21. Train Station'\n",
      " '22. Restaurant' '23. Court' '24. School' '25. Office' '26. University'\n",
      " '27. Park' '39. Key' '40. I' '40. Paint' '41. Letter' '41. you'\n",
      " '42. Paper' '42. he' '43. Lock' '43. she' '44. Telephone' '44. it'\n",
      " '45. Bag' '45. we' '46. Box' '46. you (plural)' '47. Gift' '47. they'\n",
      " '48. Card' '48. Hello' '49. How are you' '49. Ring' '50. Alright'\n",
      " '50. Tool' '51. Good Morning' '52. Good afternoon' '58. Son'\n",
      " '59. Daughter' '60. Mother' '61. Father' '62. Parent' '63. Baby'\n",
      " '64. Man' '65. Woman' '66. Brother' '67. Sister' '84. Teacher'\n",
      " '85. Student' '86. Lawyer' '87. Doctor' '88. Patient' '89. Waiter'\n",
      " '90. Secretary' '91. Priest']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "print(\"Classes:\", label_encoder.classes_)  # list of your 50 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bfa8853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stavya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">362,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,445</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m225\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m362,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m53\u001b[0m)             │         \u001b[38;5;34m3,445\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">538,549</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m538,549\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">538,549</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m538,549\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Masking\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0.0, input_shape=(110, 225)))  # mask padded zeros\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a433ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.0132 - loss: 3.9992 - val_accuracy: 0.0318 - val_loss: 3.9652\n",
      "Epoch 2/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.0199 - loss: 3.9636 - val_accuracy: 0.0227 - val_loss: 3.9570\n",
      "Epoch 3/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.0269 - loss: 3.9464 - val_accuracy: 0.0477 - val_loss: 3.7876\n",
      "Epoch 4/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.0324 - loss: 3.7739 - val_accuracy: 0.0477 - val_loss: 3.6009\n",
      "Epoch 5/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.0563 - loss: 3.6082 - val_accuracy: 0.0818 - val_loss: 3.3408\n",
      "Epoch 6/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.0796 - loss: 3.3865 - val_accuracy: 0.1159 - val_loss: 3.1346\n",
      "Epoch 7/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.1093 - loss: 3.2188 - val_accuracy: 0.1182 - val_loss: 2.9772\n",
      "Epoch 8/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.1479 - loss: 3.0576 - val_accuracy: 0.1705 - val_loss: 2.8473\n",
      "Epoch 9/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.1729 - loss: 2.9386 - val_accuracy: 0.1750 - val_loss: 2.7745\n",
      "Epoch 10/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.1657 - loss: 2.8372 - val_accuracy: 0.2114 - val_loss: 2.6021\n",
      "Epoch 11/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.1850 - loss: 2.6890 - val_accuracy: 0.2795 - val_loss: 2.4311\n",
      "Epoch 12/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.2170 - loss: 2.5730 - val_accuracy: 0.2659 - val_loss: 2.4312\n",
      "Epoch 13/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.2582 - loss: 2.4524 - val_accuracy: 0.3068 - val_loss: 2.2810\n",
      "Epoch 14/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.2624 - loss: 2.3897 - val_accuracy: 0.3773 - val_loss: 2.1379\n",
      "Epoch 15/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.3139 - loss: 2.1909 - val_accuracy: 0.3841 - val_loss: 2.0762\n",
      "Epoch 16/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.3115 - loss: 2.2101 - val_accuracy: 0.4182 - val_loss: 2.0154\n",
      "Epoch 17/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.3483 - loss: 2.1201 - val_accuracy: 0.4477 - val_loss: 1.8406\n",
      "Epoch 18/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.4048 - loss: 1.9093 - val_accuracy: 0.4364 - val_loss: 1.7875\n",
      "Epoch 19/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.3747 - loss: 1.9730 - val_accuracy: 0.4545 - val_loss: 1.8016\n",
      "Epoch 20/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.4398 - loss: 1.8089 - val_accuracy: 0.5250 - val_loss: 1.5915\n",
      "Epoch 21/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.4630 - loss: 1.6669 - val_accuracy: 0.5364 - val_loss: 1.5539\n",
      "Epoch 22/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.4942 - loss: 1.6060 - val_accuracy: 0.5545 - val_loss: 1.4439\n",
      "Epoch 23/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.4971 - loss: 1.5370 - val_accuracy: 0.5114 - val_loss: 1.5095\n",
      "Epoch 24/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.5136 - loss: 1.5176 - val_accuracy: 0.6068 - val_loss: 1.2756\n",
      "Epoch 25/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.5609 - loss: 1.3897 - val_accuracy: 0.6182 - val_loss: 1.2789\n",
      "Epoch 26/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.5758 - loss: 1.3411 - val_accuracy: 0.6364 - val_loss: 1.1962\n",
      "Epoch 27/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.5993 - loss: 1.2692 - val_accuracy: 0.6455 - val_loss: 1.1832\n",
      "Epoch 28/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.6116 - loss: 1.2390 - val_accuracy: 0.6341 - val_loss: 1.1550\n",
      "Epoch 29/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.6167 - loss: 1.1971 - val_accuracy: 0.6659 - val_loss: 1.0432\n",
      "Epoch 30/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.6537 - loss: 1.0797 - val_accuracy: 0.7182 - val_loss: 0.9292\n",
      "Epoch 31/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.6842 - loss: 0.9855 - val_accuracy: 0.7000 - val_loss: 0.8918\n",
      "Epoch 32/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.6985 - loss: 0.9486 - val_accuracy: 0.7545 - val_loss: 0.8305\n",
      "Epoch 33/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.6871 - loss: 0.9793 - val_accuracy: 0.7636 - val_loss: 0.7896\n",
      "Epoch 34/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.7210 - loss: 0.8710 - val_accuracy: 0.7659 - val_loss: 0.7638\n",
      "Epoch 35/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.7137 - loss: 0.8574 - val_accuracy: 0.7500 - val_loss: 0.7555\n",
      "Epoch 36/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.7517 - loss: 0.7803 - val_accuracy: 0.7500 - val_loss: 0.7921\n",
      "Epoch 37/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.7421 - loss: 0.7839 - val_accuracy: 0.7705 - val_loss: 0.7427\n",
      "Epoch 38/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.7503 - loss: 0.7445 - val_accuracy: 0.7909 - val_loss: 0.6162\n",
      "Epoch 39/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.7704 - loss: 0.7029 - val_accuracy: 0.8318 - val_loss: 0.5721\n",
      "Epoch 40/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.8006 - loss: 0.6500 - val_accuracy: 0.8273 - val_loss: 0.5942\n",
      "Epoch 41/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.7869 - loss: 0.6673 - val_accuracy: 0.8432 - val_loss: 0.5621\n",
      "Epoch 42/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.7976 - loss: 0.6247 - val_accuracy: 0.8159 - val_loss: 0.5589\n",
      "Epoch 43/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.8205 - loss: 0.5612 - val_accuracy: 0.8023 - val_loss: 0.5249\n",
      "Epoch 44/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8242 - loss: 0.5376 - val_accuracy: 0.8386 - val_loss: 0.4508\n",
      "Epoch 45/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.8466 - loss: 0.4850 - val_accuracy: 0.8614 - val_loss: 0.3996\n",
      "Epoch 46/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8462 - loss: 0.4683 - val_accuracy: 0.8227 - val_loss: 0.5615\n",
      "Epoch 47/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.7948 - loss: 0.5923 - val_accuracy: 0.8795 - val_loss: 0.4144\n",
      "Epoch 48/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.8743 - loss: 0.4075 - val_accuracy: 0.8773 - val_loss: 0.3648\n",
      "Epoch 49/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.8819 - loss: 0.3984 - val_accuracy: 0.8614 - val_loss: 0.4231\n",
      "Epoch 50/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.8681 - loss: 0.4175 - val_accuracy: 0.8386 - val_loss: 0.4722\n",
      "Epoch 51/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.8719 - loss: 0.4057 - val_accuracy: 0.8795 - val_loss: 0.3822\n",
      "Epoch 52/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8775 - loss: 0.3832 - val_accuracy: 0.8409 - val_loss: 0.4989\n",
      "Epoch 53/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8741 - loss: 0.3862 - val_accuracy: 0.8977 - val_loss: 0.2770\n",
      "Epoch 54/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.9035 - loss: 0.3142 - val_accuracy: 0.9023 - val_loss: 0.2984\n",
      "Epoch 55/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.8875 - loss: 0.3295 - val_accuracy: 0.8182 - val_loss: 0.4981\n",
      "Epoch 56/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8653 - loss: 0.3911 - val_accuracy: 0.9205 - val_loss: 0.2706\n",
      "Epoch 57/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.8948 - loss: 0.3529 - val_accuracy: 0.9159 - val_loss: 0.2967\n",
      "Epoch 58/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8929 - loss: 0.3207 - val_accuracy: 0.8750 - val_loss: 0.4419\n",
      "Epoch 59/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8943 - loss: 0.3619 - val_accuracy: 0.9023 - val_loss: 0.3165\n",
      "Epoch 60/60\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.8996 - loss: 0.3015 - val_accuracy: 0.8750 - val_loss: 0.3348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=60,  # feel free to tune\n",
    "                    batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58052f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"isl_bilstm_model_v2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16360763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"label_encoder_v2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb49f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "# Load model and encoder\n",
    "model = load_model(\"D:/code/Mini/pro v5/isl_bilstm_model_v2.h5\")\n",
    "\n",
    "with open(\"D:/code/Mini/pro v5/label_encoder_v2.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb7be23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sign(video_path):\n",
    "    sequence = extract_sequence_from_video(video_path, max_frames=110)\n",
    "\n",
    "    # Pad or truncate\n",
    "    if sequence.shape[0] < 110:\n",
    "        pad_len = 117 - sequence.shape[0]\n",
    "        sequence = np.vstack((sequence, np.zeros((pad_len, 225))))\n",
    "    else:\n",
    "        sequence = sequence[:110]\n",
    "\n",
    "    sequence = np.expand_dims(sequence, axis=0)  # shape: (1, 117, 225)\n",
    "    prediction = model.predict(sequence)\n",
    "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "\n",
    "    return predicted_label[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af308d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Predicted Word: 47. they\n"
     ]
    }
   ],
   "source": [
    "predicted_word = predict_sign(\"D:/code/Mini/Final data/47. they/MVI_0026.MOV\")\n",
    "print(\"Predicted Word:\", predicted_word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
